{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Tweets\n",
    "\n",
    "A tweet consists of many data fields. [Here is an example](https://gist.github.com/arapat/03d02c9b327e6ff3f6c3c5c602eeaf8b). You can learn all about them in the Twitter API doc. We are going to briefly introduce only the data fields that will be used in this homework.\n",
    "\n",
    "* `created_at`: Posted time of this tweet (time zone is included)\n",
    "* `id_str`: Tweet ID - we recommend using `id_str` over using `id` as Tweet IDs, becauase `id` is an integer and may bring some overflow problems.\n",
    "* `text`: Tweet content\n",
    "* `user`: A JSON object for information about the author of the tweet\n",
    "    * `id_str`: User ID\n",
    "    * `name`: User name (may contain spaces)\n",
    "    * `screen_name`: User screen name (no spaces)\n",
    "* `retweeted_status`: A JSON object for information about the retweeted tweet (i.e. this tweet is not original but retweeteed some other tweet)\n",
    "    * All data fields of a tweet except `retweeted_status`\n",
    "* `entities`: A JSON object for all entities in this tweet\n",
    "    * `hashtags`: An array for all the hashtags that are mentioned in this tweet\n",
    "    * `urls`: An array for all the URLs that are mentioned in this tweet\n",
    "\n",
    "\n",
    "## Data source\n",
    "\n",
    "All tweets are collected using the [Twitter Streaming API](https://dev.twitter.com/streaming/overview).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Load data to a RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%pylab inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "./Data/t1/1.txt\n",
      "2\n",
      "./Data/t1/2.txt\n",
      "3\n",
      "./Data/t1/3.txt\n",
      "4\n",
      "./Data/t1/4.txt\n",
      "2466\n",
      "1325\n",
      "609\n",
      "1048\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# (Nishant:  add code to take one time sliced in one time and delete after use)\n",
    "\n",
    "\n",
    "count =0\n",
    "with open('./Data/sliced.txt') as f:\n",
    "    for l in f.readlines():\n",
    "        count = count+1\n",
    "        print count;\n",
    "        if len(l.strip()) is not 0:\n",
    "            file1 = l.strip()\n",
    "            print file1\n",
    "            if count == 1:\n",
    "                doc1 = sc.textFile(file1).cache()\n",
    "            if count == 2:\n",
    "                doc2 = sc.textFile(file1).cache()\n",
    "            if count == 3:\n",
    "                doc3 = sc.textFile(file1).cache()\n",
    "            if count == 4:\n",
    "                doc4 = sc.textFile(file1).cache()\n",
    "        # if count == 5:\n",
    "            #    doc5 = sc.textFile(file1).cache()\n",
    "    \n",
    "print doc1.count()\n",
    "print doc2.count()\n",
    "print doc3.count()\n",
    "print doc4.count()\n",
    "#print doc5.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Parse JSON strings to JSON objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has built-in support for JSON.\n",
    "\n",
    "**UPDATE:** Python built-in json library is too slow. In our experiment, 70% of the total running time is spent on parsing tweets. Therefore we recommend using [ujson](https://pypi.python.org/pypi/ujson) instead of json. It is at least 15x faster than the built-in json library according to our tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broken tweets and irrelevant messages\n",
    "\n",
    "The data of this assignment may contain broken tweets (invalid JSON strings). So make sure that your code is robust for such cases.\n",
    "\n",
    "In addition, some lines in the input file might not be tweets, but messages that the Twitter server sent to the developer (such as [limit notices](https://dev.twitter.com/streaming/overview/messages-types#limit_notices)). Your program should also ignore these messages.\n",
    "\n",
    "*Hint:* [Catch the ValueError](http://stackoverflow.com/questions/11294535/verify-if-a-string-is-json-in-python)\n",
    "\n",
    "\n",
    "(1) Parse raw JSON tweets to obtain valid JSON objects. From all valid tweets, construct a pair RDD of `(user_id, text)`, where `user_id` is the `id_str` data field of the `user` dictionary (read [Tweets](#Tweets) section above), `text` is the `text` data field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ujson\n",
    "\n",
    "def safe_parse(x):\n",
    "    try:\n",
    "        json_object = ujson.loads(x)\n",
    "    except ValueError, e:\n",
    "        pass # invalid json\n",
    "    else:\n",
    "        return json_object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile('[%s]' % re.escape('!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc1text = doc1.filter(lambda x: 'user' in x and 'id_str' in x and 'text' in x).map(safe_parse)\\\n",
    "        .map(lambda x: regex.sub('', x[\"text\"].lower()).encode('utf-8')).cache()\n",
    "doc2text = doc2.filter(lambda x: 'user' in x and 'id_str' in x and 'text' in x).map(safe_parse)\\\n",
    "        .map(lambda x: regex.sub('', x[\"text\"].lower()).encode('utf-8')).cache()\n",
    "doc3text = doc3.filter(lambda x: 'user' in x and 'id_str' in x and 'text' in x).map(safe_parse)\\\n",
    "        .map(lambda x: regex.sub('', x[\"text\"].lower()).encode('utf-8')).cache()\n",
    "doc4text = doc4.filter(lambda x: 'user' in x and 'id_str' in x and 'text' in x).map(safe_parse)\\\n",
    "        .map(lambda x: regex.sub('', x[\"text\"].lower()).encode('utf-8')).cache()\n",
    "#doc5text = doc5.filter(lambda x: 'user' in x and 'id_str' in x and 'text' in x).map(safe_parse)\\\n",
    " #       .map(lambda x: regex.sub('', x[\"text\"].lower()).encode('utf-8')).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Punctuation Stopwords And Strip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#alwaystrump  trump2016 #trumptrain #makeamericagreatagain vote trump  httpstcosadz1nys5o\n",
      "i donated @berniesanders #feelthebern #notmeus httpstcoqssmygivwd\n",
      "@carminezozzora @jaredwyand @hillaryclinton she is divisive there will be no coming together under #hillary she refers to gop as the enemy\n",
      "mt @texasshebandit a vote for #tedcruz is a vote for conservatism httpstcobfhdqvivvw #cruzcrew #pjnet\n"
     ]
    }
   ],
   "source": [
    "print doc1text.first()\n",
    "print doc2text.first()\n",
    "print doc3text.first()\n",
    "print doc4text.first()\n",
    "#print doc5text.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## removing punctuation stopwords and https\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "stop_words =set(stopwords.words(\"english\"))\n",
    "stop_words|=set([\"edu\", \"com\", \"also\", \"still\", \"anyone\", \"cc\" , \"ca\", \"us\", \"much\", \"even\", \"would\", \"see\", \"rt\", 'is', 'of'])\n",
    "st = PorterStemmer()\n",
    "\n",
    "#IMP: Put yout nltk_data folder in /usr/local/share for it to work :)\n",
    "\n",
    "def getwords(tweet):\n",
    "    return [st.stem(x) for x in tweet if not ( x.startswith('htt') or x.startswith('@') or x in stop_words or x is ' ')]\n",
    "\n",
    "punc = string.punctuation+\"\\n\"\n",
    "\n",
    "tweetNeat1 = doc1text.map(lambda s: getwords(s.decode('utf-8').split(\" \"))).filter(lambda x: len(x)>0).map(lambda x: filter(None,x))\n",
    "tweetNeat2 = doc2text.map(lambda s: getwords(s.decode('utf-8').split(\" \"))).filter(lambda x: len(x)>0).map(lambda x: filter(None,x))\n",
    "tweetNeat3 = doc3text.map(lambda s: getwords(s.decode('utf-8').split(\" \"))).filter(lambda x: len(x)>0).map(lambda x: filter(None,x))\n",
    "tweetNeat4 = doc4text.map(lambda s: getwords(s.decode('utf-8').split(\" \"))).filter(lambda x: len(x)>0).map(lambda x: filter(None,x))\n",
    "#tweetNeat5 = doc5text.map(lambda s: getwords(s.decode('utf-8').split(\" \"))).filter(lambda x: len(x)>0).map(lambda x: filter(None,x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Dictionary of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4973\n"
     ]
    }
   ],
   "source": [
    "## make dictionary \n",
    "fulltweet = tweetNeat1+tweetNeat2+tweetNeat3+tweetNeat4\n",
    "#+tweetNeat5\n",
    "vocab = fulltweet.flatMap(lambda x: x).distinct().collect()\n",
    "\n",
    "V= len(vocab)\n",
    "print V\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# If small dictionary is needed\n",
    "vocabSmall = tweetNeat.flatMap(lambda x: x).map(lambda x : (x,1)).reduceByKey(lambda a, b: a+b).map(lambda (c,v):(v,c)).sortByKey(False).map(lambda (c,v):v).take(10000)\n",
    "Or dont sort and filter very frequent and very less frequent words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documents from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetList = 4*[[]]\n",
    "\n",
    "tweetList[0] = tweetNeat1.flatMap(lambda x:x).collect()\n",
    "tweetList[1] = tweetNeat2.flatMap(lambda x:x).collect()\n",
    "tweetList[2] = tweetNeat3.flatMap(lambda x:x).collect()\n",
    "tweetList[3] = tweetNeat4.flatMap(lambda x:x).collect()\n",
    "#tweetList[4] = tweetNeat5.flatMap(lambda x:x).collect()\n",
    "\n",
    "D = len(tweetList)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'#alwaystrump',\n",
       " u'trump2016',\n",
       " u'#trumptrain',\n",
       " u'#makeamericagreatagain',\n",
       " u'vote',\n",
       " u'trump',\n",
       " u'#trump',\n",
       " u'#trump2016',\n",
       " u'sen',\n",
       " u'jeff',\n",
       " u'session',\n",
       " u'endors',\n",
       " u'donald',\n",
       " u'trump',\n",
       " u'isnt',\n",
       " u'campaign',\n",
       " u'movement',\n",
       " u'#trump2016',\n",
       " u'#alprimari',\n",
       " u'donald',\n",
       " u'j',\n",
       " u'trump',\n",
       " u'49rubio',\n",
       " u'cruz',\n",
       " u'carson',\n",
       " u'kasich',\n",
       " u'47#makeamericagreatagain',\n",
       " u'#trump2016',\n",
       " u'#trumptrain\\U0001f682\\U0001f1fa\\U0001f1f8\\U0001f1fa\\U0001f1f8\\U0001f1fa\\U0001f1f8\\U0001f1fa\\U0001f1f8\\U0001f1fa\\U0001f1f8\\U0001f1fa\\U0001f1f8',\n",
       " u'silent',\n",
       " u'major',\n",
       " u'stand',\n",
       " u'#trump',\n",
       " u'battl',\n",
       " u'msm',\n",
       " u'#alwaystrump',\n",
       " u'#neverrubio',\n",
       " u'#nevercruz',\n",
       " u'bill',\n",
       " u'prevent',\n",
       " u'sanctuari',\n",
       " u'citi',\n",
       " u'florida',\n",
       " u'die',\n",
       " u'marco',\n",
       " u'rubio',\n",
       " u'watch',\n",
       " u'#rubio',\n",
       " u'#alwaystru\\u2026',\n",
       " u'corrupt',\n",
       " u'incarn',\n",
       " u'#trump2016',\n",
       " u'#secprimari',\n",
       " u'former',\n",
       " u'ted',\n",
       " u'cruz',\n",
       " u'support',\n",
       " u'vote',\n",
       " u'donald',\n",
       " u'trump',\n",
       " u'#supertuesday',\n",
       " u'trust',\n",
       " u'trump',\n",
       " u'#trumptrain',\n",
       " u'#alwaystrump',\n",
       " u'hillari',\n",
       " u'could',\n",
       " u'lose',\n",
       " u'trump',\n",
       " u'democrat',\n",
       " u'new',\n",
       " u'york#makeamericagreatagain',\n",
       " u'#trump2016httpstcofqr48cvibt',\n",
       " u'hillari',\n",
       " u'could',\n",
       " u'lose',\n",
       " u'trump',\n",
       " u'democrat',\n",
       " u'new',\n",
       " u'york#makeamericagreatagain',\n",
       " u'#trump2016httpstcofqr48cvibt',\n",
       " u'noth',\n",
       " u'kill',\n",
       " u'go8',\n",
       " u'bill',\n",
       " u'dem',\n",
       " u'couldnt',\n",
       " u'blame',\n",
       " u'republican',\n",
       " u'huhhttpstcob9wgouk278#secprimari',\n",
       " u'#super\\u2026',\n",
       " u'hillari',\n",
       " u'could',\n",
       " u'lose',\n",
       " u'trump',\n",
       " u'democrat',\n",
       " u'new',\n",
       " u'york#makeamericagreatagain',\n",
       " u'#trump2016httpstcofqr48cvibt',\n",
       " u'announc',\n",
       " u'run',\n",
       " u'congress',\n",
       " u'ny11',\n",
       " u'100',\n",
       " u'pro',\n",
       " u'candid',\n",
       " u'#trump',\n",
       " u'#trump2016',\n",
       " u'#buildthewal',\n",
       " u'amp',\n",
       " u'lawsuit',\n",
       " u'set',\n",
       " u'11',\n",
       " u'friday',\n",
       " u'march',\n",
       " u'4th',\n",
       " u'#fl',\n",
       " u'#alwaystrump',\n",
       " u'read',\n",
       " u'join',\n",
       " u'columbu',\n",
       " u'ohio',\n",
       " u'tomorrow#makeamericagreatagain',\n",
       " u'#trump2016httpstcoyfhzd55gd9',\n",
       " u'#gingrich',\n",
       " u'stop',\n",
       " u'trump',\n",
       " u'amp',\n",
       " u'assault',\n",
       " u'charact',\n",
       " u'nonsense#trump2016#secprimaryhttpstcoifwystzbl8',\n",
       " u'hey',\n",
       " u'nasti',\n",
       " u'jab',\n",
       " u'christi',\n",
       " u'gov',\n",
       " u'put',\n",
       " u'full',\n",
       " u'weight',\n",
       " u'behind',\n",
       " u'larger',\n",
       " u'valu',\n",
       " u'christi',\n",
       " u'endors',\n",
       " u'#alwaystrump',\n",
       " u'stand',\n",
       " u'springfield',\n",
       " u'plaza',\n",
       " u'springfieldva',\n",
       " u'tri',\n",
       " u'get',\n",
       " u'voter',\n",
       " u'mr',\n",
       " u'trump',\n",
       " u'#trump2016',\n",
       " u'trump',\n",
       " u'97',\n",
       " u'chanc',\n",
       " u'beat',\n",
       " u'clintonstoni',\n",
       " u'brook',\n",
       " u'univers',\n",
       " u'professor',\n",
       " u'helmut',\n",
       " u'north#makeamericagreatagain',\n",
       " u'white',\n",
       " u'supremacist',\n",
       " u'group',\n",
       " u'gop',\n",
       " u'christian',\n",
       " u'tea',\n",
       " u'parti',\n",
       " u'gunown',\n",
       " u'disagre',\n",
       " u'lef\\u2026',\n",
       " u'ben',\n",
       " u'carson',\n",
       " u'intend',\n",
       " u'stay',\n",
       " u'gop',\n",
       " u'presidenti',\n",
       " u'race',\n",
       " u'fox',\n",
       " u'news',\n",
       " u'#alwaystrump',\n",
       " u'#votetrumps\\u2026',\n",
       " u'deliber',\n",
       " u'viciou',\n",
       " u'calcul',\n",
       " u'hatemong',\n",
       " u'libel',\n",
       " u'slander',\n",
       " u'sue',\n",
       " u'bastard',\n",
       " u'#trump2016',\n",
       " u'#alwaystrump',\n",
       " u'#trump',\n",
       " u'#alwaystrump',\n",
       " u'#makeamericagreatagain',\n",
       " u'mitt',\n",
       " u'romney',\n",
       " u'refus',\n",
       " u'attack',\n",
       " u'barack',\n",
       " u'obama',\n",
       " u'gladli',\n",
       " u'attack',\n",
       " u'lead',\n",
       " u'republican',\n",
       " u'candid',\n",
       " u'#makeamericagreatagain',\n",
       " u'dont',\n",
       " u'want',\n",
       " u'hear',\n",
       " u'crass',\n",
       " u'trump',\n",
       " u'ok#drugtestrubio',\n",
       " u'#alwaystrump',\n",
       " u'#supertuesday',\n",
       " u'#marco',\n",
       " u'make',\n",
       " u'drop',\n",
       " u'offer',\n",
       " u'scotu',\n",
       " u'appoint',\n",
       " u'#alwaystrumpread',\n",
       " u'trump',\n",
       " u'support',\n",
       " u'#2a',\n",
       " u'right',\n",
       " u'peopl',\n",
       " u'keep',\n",
       " u'bear',\n",
       " u'arm',\n",
       " u'shall',\n",
       " u'infring',\n",
       " u'upon',\n",
       " u'period\\u201d',\n",
       " u'sad',\n",
       " u'day',\n",
       " u'use',\n",
       " u'realli',\n",
       " u'like',\n",
       " u'fnc',\n",
       " u'trick',\n",
       " u'#alwaystrump',\n",
       " u'\\u2b06\\ufe0f',\n",
       " u'#trump',\n",
       " u'v',\n",
       " u'#sander',\n",
       " u'poll',\n",
       " u'\\u2b06\\ufe0f',\n",
       " u'vote',\n",
       " u'#trump2016',\n",
       " u'#bernie2016',\n",
       " u'#makeamericagreatagain',\n",
       " u'#feelthebern',\n",
       " u'#tcot',\n",
       " u'#uniteblu',\n",
       " u'#gop',\n",
       " u'#bernieorbust',\n",
       " u'american',\n",
       " u'student',\n",
       " u'detain',\n",
       " u'north',\n",
       " u'korea',\n",
       " u'wouldv',\n",
       " u'alreadi',\n",
       " u'releas',\n",
       " u'#trump',\n",
       " u'presid',\n",
       " u'#alwaystrump',\n",
       " u'lie',\n",
       " u'#makeamericagreatagain',\n",
       " u'#wakeupamerica',\n",
       " u'vote',\n",
       " u'trump',\n",
       " u'vote',\n",
       " u'statu',\n",
       " u'quo',\n",
       " u'go',\n",
       " u'texa',\n",
       " u'\\u2b50',\n",
       " u'go',\n",
       " u'#trump',\n",
       " u'#makeamericagreatagain\\u263a',\n",
       " u'#dtmag',\n",
       " u'trump',\n",
       " u'get',\n",
       " u'john',\n",
       " u'oliv',\n",
       " u'treatment',\n",
       " u'#trump2016',\n",
       " u'#johnoliv',\n",
       " u'\\U0001f4a52nd',\n",
       " u'ralli',\n",
       " u'monday\\U0001f389donald',\n",
       " u'trump',\n",
       " u'valdosta',\n",
       " u'ga\\U0001f3896',\n",
       " u'pm',\n",
       " u'est#votetrumpga#secprimary#trump2016#trumptrain\\U0001f682\\U0001f1fa\\U0001f1f8\\U0001f1fa\\U0001f1f8httpstc\\u2026',\n",
       " u'mitt',\n",
       " u'romney',\n",
       " u'refus',\n",
       " u'attack',\n",
       " u'barack',\n",
       " u'obama',\n",
       " u'gladli',\n",
       " u'attack',\n",
       " u'lead',\n",
       " u'republican',\n",
       " u'candid',\n",
       " u'#makeamericagreatagain',\n",
       " u'could',\n",
       " u'put',\n",
       " u'hillari',\n",
       " u'defens',\n",
       " u'instead',\n",
       " u'give',\n",
       " u'ammunitionhttpstco8sdka27sih#trump2016',\n",
       " u'trump',\n",
       " u'gotham',\n",
       " u'shocker',\n",
       " u'poll',\n",
       " u'data',\n",
       " u'show',\n",
       " u'new',\n",
       " u'york',\n",
       " u'play',\n",
       " u'hillari',\n",
       " u'troubl',\n",
       " u'#alwayst\\u2026',\n",
       " u'#alwaystrump',\n",
       " u'trump',\n",
       " u'support',\n",
       " u'#2a',\n",
       " u'right',\n",
       " u'peopl',\n",
       " u'keep',\n",
       " u'bear',\n",
       " u'arm',\n",
       " u'shall',\n",
       " u'infring',\n",
       " u'upon',\n",
       " u'period\\u201d',\n",
       " u'#trump',\n",
       " u'#makeamericagreatagain',\n",
       " u'freedom',\n",
       " u'siegevot',\n",
       " u'#trumpu',\n",
       " u'christian',\n",
       " u'judeo',\n",
       " u'nation',\n",
       " u'white',\n",
       " u'media',\n",
       " u'desper',\n",
       " u'beat',\n",
       " u'#trump2016',\n",
       " u'play',\n",
       " u'race',\n",
       " u'card',\n",
       " u'brink',\n",
       " u'race',\n",
       " u'war#trump',\n",
       " u'hate#cnn',\n",
       " u'#foxnew',\n",
       " u'#msnbc',\n",
       " u'white',\n",
       " u'supremacist',\n",
       " u'group',\n",
       " u'gop',\n",
       " u'christian',\n",
       " u'tea',\n",
       " u'parti',\n",
       " u'gunown',\n",
       " u'disagre',\n",
       " u'lef\\u2026',\n",
       " u'getreadi',\n",
       " u'pre',\n",
       " u'#alwaystrump',\n",
       " u'4',\n",
       " u'productiveyear',\n",
       " u'record',\n",
       " u'america',\n",
       " u'#dontbelievemejustwatch',\n",
       " u'dont',\n",
       " u'want',\n",
       " u'hear',\n",
       " u'crass',\n",
       " u'trump',\n",
       " u'ok#drugtestrubio',\n",
       " u'#alwaystrump',\n",
       " u'#supertuesday',\n",
       " u'#marco',\n",
       " u'join',\n",
       " u'columbu',\n",
       " u'ohio',\n",
       " u'tomorrow#makeamericagreatagain',\n",
       " u'#trump2016httpstcoyfhzd55gd9',\n",
       " u'ye',\n",
       " u'fire',\n",
       " u'celebr',\n",
       " u'apprentic',\n",
       " u'he',\n",
       " u'fire',\n",
       " u'ass',\n",
       " u'#makeamericagrea\\u2026',\n",
       " u'\\U0001f4a51st',\n",
       " u'ralli',\n",
       " u'today\\U0001f389donald',\n",
       " u'trump',\n",
       " u'radford',\n",
       " u'uni',\n",
       " u'va\\U0001f38912',\n",
       " u'pm',\n",
       " u'est#votetrumpva#secprimary#trump2016#trumptrain\\U0001f682\\U0001f1fa\\U0001f1f8https\\u2026',\n",
       " u'ted',\n",
       " u'cruz',\n",
       " u'expect',\n",
       " u'win',\n",
       " u'state',\n",
       " u'#texa',\n",
       " u'expect',\n",
       " u'win',\n",
       " u'#sc',\n",
       " u'evangel',\n",
       " u'vote',\n",
       " u'#alwaystrump',\n",
       " u'#trump\\u2026',\n",
       " u'virginia#supertuesday',\n",
       " u'\\U0001f1fa\\U0001f1f8#makeamericagreatagain\\U0001f1fa\\U0001f1f8\\u2764\\ufe0f\\U0001f1fa\\U0001f1f8\\u2764\\ufe0f\\U0001f1fa\\U0001f1f8\\u2764\\ufe0f\\U0001f1fa\\U0001f1f8\\u2764\\ufe0f\\U0001f1fa\\U0001f1f8\\u2764\\ufe0f\\U0001f1fa\\U0001f1f8',\n",
       " u'hillari',\n",
       " u'could',\n",
       " u'lose',\n",
       " u'trump',\n",
       " u'democrat',\n",
       " u'new',\n",
       " u'york#makeamericagreatagain',\n",
       " u'#trump2016httpstcofqr48cvibt',\n",
       " u'msm',\n",
       " u'glass',\n",
       " u'ceil',\n",
       " u'peopl',\n",
       " u'take',\n",
       " u'countri',\n",
       " u'back',\n",
       " u'#alwaystrump',\n",
       " u'#secprimari',\n",
       " u'supertuesday',\n",
       " u'parti',\n",
       " u'rival',\n",
       " u'attack',\n",
       " u'trump',\n",
       " u'condemin',\n",
       " u'david',\n",
       " u'duke',\n",
       " u'#election2016',\n",
       " u'#trump2016',\n",
       " u'surpris',\n",
       " u'#cruz',\n",
       " u'opposit',\n",
       " u'american',\n",
       " u'want',\n",
       " u'vote',\n",
       " u'#trump',\n",
       " u'#texa',\n",
       " u'#secprimari',\n",
       " u'#arkansa',\n",
       " u'#alwaystrump',\n",
       " u'live',\n",
       " u'stream',\n",
       " u'trump',\n",
       " u'ralli',\n",
       " u'radford',\n",
       " u'va',\n",
       " u'22916',\n",
       " u'#makeamericagreatagain',\n",
       " u'#alwaystrump',\n",
       " u'ted',\n",
       " u'cruz',\n",
       " u'expect',\n",
       " u'win',\n",
       " u'state',\n",
       " u'#texa',\n",
       " u'expect',\n",
       " u'win',\n",
       " u'#sc',\n",
       " u'evangel',\n",
       " u'vote',\n",
       " u'#alwaystrump',\n",
       " u'#trump\\u2026',\n",
       " u'hillari',\n",
       " u'could',\n",
       " u'lose',\n",
       " u'trump',\n",
       " u'democrat',\n",
       " u'new',\n",
       " u'york#makeamericagreatagain',\n",
       " u'#trump2016httpstcofqr48cvibt',\n",
       " u'ben',\n",
       " u'carson',\n",
       " u'intend',\n",
       " u'stay',\n",
       " u'gop',\n",
       " u'presidenti',\n",
       " u'race',\n",
       " u'fox',\n",
       " u'news',\n",
       " u'#alwaystrump',\n",
       " u'#votetrumps\\u2026',\n",
       " u'reagan',\n",
       " u'disavow',\n",
       " u'klan',\n",
       " u'endors',\n",
       " u'like',\n",
       " u'trump',\n",
       " u'friday',\n",
       " u'liber',\n",
       " u'tactic',\n",
       " u'use',\n",
       " u'#alwaystrump',\n",
       " u'new',\n",
       " u'cnnorc',\n",
       " u'polltrump',\n",
       " u'33',\n",
       " u'rubio',\n",
       " u'cruz',\n",
       " u'#tx',\n",
       " u'#fl',\n",
       " u'#ok',\n",
       " u'#al',\n",
       " u'#tn',\n",
       " u'#va',\n",
       " u'#co',\n",
       " u'#trump2016',\n",
       " u'#alwaystrump',\n",
       " u'trump',\n",
       " u'build',\n",
       " u'wall',\n",
       " u'#alwaystrump',\n",
       " u'#texasprimari',\n",
       " u'#secprimari',\n",
       " u'#trumpsess',\n",
       " u'white',\n",
       " u'supremacist',\n",
       " u'group',\n",
       " u'republican',\n",
       " u'parti',\n",
       " u'gunown',\n",
       " u'tea',\n",
       " u'parti',\n",
       " u'disagre',\n",
       " u'them#se\\u2026',\n",
       " u'donald',\n",
       " u'trump',\n",
       " u'crush',\n",
       " u'#rubio#cruz',\n",
       " u'earn',\n",
       " u'49',\n",
       " u'cnn',\n",
       " u'natl',\n",
       " u'poll#alwaystrump#secprimaryhttpstcowfl8la2srn',\n",
       " u'#alwaystrump',\n",
       " u'new',\n",
       " u'poll',\n",
       " u'show',\n",
       " u'#trump',\n",
       " u'extend',\n",
       " u'lead',\n",
       " u'#trumptrain',\n",
       " u'#supertuesday',\n",
       " u'#makeamericagreatagain',\n",
       " u'donald',\n",
       " u'trump',\n",
       " u'crush',\n",
       " u'#rubio#cruz',\n",
       " u'earn',\n",
       " u'49',\n",
       " u'cnn',\n",
       " u'natl',\n",
       " u'poll#alwaystrump#secprimaryhttpstcowfl8la2srn',\n",
       " u'hillari',\n",
       " u'could',\n",
       " u'lose',\n",
       " u'trump',\n",
       " u'democrat',\n",
       " u'new',\n",
       " u'york#makeamericagreatagain',\n",
       " u'#trump2016httpstcofqr48cvibt',\n",
       " u'that',\n",
       " u'real',\n",
       " u'true',\n",
       " u'american',\n",
       " u'#makeamericagreatagain',\n",
       " u'despit',\n",
       " u'lie',\n",
       " u'despit',\n",
       " u'bull',\n",
       " u'shit',\n",
       " u'#alwaystrump',\n",
       " u'donald',\n",
       " u'trump',\n",
       " u'crush',\n",
       " u'#rubio#cruz',\n",
       " u'earn',\n",
       " u'49',\n",
       " u'cnn',\n",
       " u'natl',\n",
       " u'poll#alwaystrump#secprimaryhttpstcowfl8la2srn',\n",
       " u'ted',\n",
       " u'cruz',\n",
       " u'expect',\n",
       " u'win',\n",
       " u'state',\n",
       " u'#texa',\n",
       " u'expect',\n",
       " u'win',\n",
       " u'#sc',\n",
       " u'evangel',\n",
       " u'vote',\n",
       " u'#alwaystrump',\n",
       " u'#trump\\u2026',\n",
       " u'sen',\n",
       " u'jeff',\n",
       " u'session',\n",
       " u'endors',\n",
       " u'donald',\n",
       " u'trump',\n",
       " u'isnt',\n",
       " u'campaign',\n",
       " u'movement',\n",
       " u'#trump2016',\n",
       " u'#alprimari',\n",
       " u'loser',\n",
       " u'cheater',\n",
       " u'liars#gopsmartset',\n",
       " u'let',\n",
       " u'start',\n",
       " u'thirdparti',\n",
       " u'candidate#alwaystrump#votetrump2016#secprimaryhttpst\\u2026',\n",
       " u'trump',\n",
       " u'support',\n",
       " u'#2a',\n",
       " u'right',\n",
       " u'peopl',\n",
       " u'keep',\n",
       " u'bear',\n",
       " u'arm',\n",
       " u'shall',\n",
       " u'infring',\n",
       " u'upon',\n",
       " u'period\\u201d',\n",
       " u'donald',\n",
       " u'trump',\n",
       " u'crush',\n",
       " u'#rubio#cruz',\n",
       " u'earn',\n",
       " u'49',\n",
       " u'cnn',\n",
       " u'natl',\n",
       " u'poll#alwaystrump#secprimaryhttpstcowfl8la2srn',\n",
       " u'havent',\n",
       " u'heard',\n",
       " u'#loon',\n",
       " u'sinc',\n",
       " u'crash',\n",
       " u'speech',\n",
       " u'sc',\n",
       " u'#supertuesday',\n",
       " u'#alwaystrump',\n",
       " u'#trump',\n",
       " u'tomorrow',\n",
       " u'super',\n",
       " u'tuesday',\n",
       " u'get',\n",
       " u'amp',\n",
       " u'vote',\n",
       " u'vote',\n",
       " u'trump',\n",
       " u'dont',\n",
       " u'wast',\n",
       " u'vote',\n",
       " u'els',\n",
       " u'#makeamericagreatagain',\n",
       " u'join',\n",
       " u'columbu',\n",
       " u'ohio',\n",
       " u'tomorrow#makeamericagreatagain',\n",
       " u'#trump2016httpstcoyfhzd55gd9',\n",
       " u'rubio',\n",
       " u'campaign',\n",
       " u'new',\n",
       " u'phrase',\n",
       " u'talk',\n",
       " u'point',\n",
       " u'trump',\n",
       " u'con',\n",
       " u'man',\n",
       " u'lol',\n",
       " u'#onlytrump',\n",
       " u'#trump2016',\n",
       " u'shouldnt',\n",
       " u'practic',\n",
       " u'honest',\n",
       " u'journalist',\n",
       " u'report',\n",
       " u'duke',\n",
       " u'didnt',\n",
       " u'endors',\n",
       " u'trump',\n",
       " u'#alwaystrump',\n",
       " u'#honestyworkstryit',\n",
       " u'join',\n",
       " u'columbu',\n",
       " u'ohio',\n",
       " u'tomorrow#makeamericagreatagain',\n",
       " u'#trump2016httpstcoyfhzd55gd9',\n",
       " u'must',\n",
       " u'continu',\n",
       " u'fight',\n",
       " u'social',\n",
       " u'mediath',\n",
       " u'peopl',\n",
       " u'strongest',\n",
       " u'tool',\n",
       " u'right',\n",
       " u'trump',\n",
       " u'2016',\n",
       " u'#alwaystrump',\n",
       " u'donald',\n",
       " u'trump',\n",
       " u'crush',\n",
       " u'#rubio#cruz',\n",
       " u'earn',\n",
       " u'49',\n",
       " u'cnn',\n",
       " u'natl',\n",
       " u'poll#alwaystrump#secprimaryhttpstcowfl8la2srn',\n",
       " u'rt@govmikehuckabe',\n",
       " u'call',\n",
       " u'gop',\n",
       " u'establish',\n",
       " u'support',\n",
       " u'#trump',\n",
       " u'vote',\n",
       " u'#alwaystrump',\n",
       " u'#arksana',\n",
       " u'#secprimari',\n",
       " u'ht\\u2026',\n",
       " u'join',\n",
       " u'columbu',\n",
       " u'ohio',\n",
       " u'tomorrow#makeamericagreatagain',\n",
       " u'#trump2016httpstco9f5pznb7va',\n",
       " u'trump',\n",
       " u'your\\u2026',\n",
       " u'let',\n",
       " u'get',\n",
       " u'#robertbyrd',\n",
       " u'trending#hillaryclinton',\n",
       " u'kkk',\n",
       " u'leader',\n",
       " u'hero',\n",
       " u'#makeamericagreatagain',\n",
       " u'liter',\n",
       " u'disgust',\n",
       " u'#secprimari',\n",
       " u'#supertuesday',\n",
       " u'#alwaystrump',\n",
       " u'#marcorubio',\n",
       " u'#marcomentum',\n",
       " u'donald',\n",
       " u'trump',\n",
       " u'crush',\n",
       " u'#rubio#cruz',\n",
       " u'earn',\n",
       " u'49',\n",
       " u'cnn',\n",
       " u'natl',\n",
       " u'poll#alwaystrump#secprimaryhttpstcowfl8la2srn',\n",
       " u'control',\n",
       " u'1',\n",
       " u'elit',\n",
       " u'stay',\n",
       " u'cours',\n",
       " u'#alwaystrump',\n",
       " u'incred',\n",
       " u'proud',\n",
       " u'call',\n",
       " u'oz',\n",
       " u'friend',\n",
       " u'oz',\n",
       " u'amp',\n",
       " u'tig',\n",
       " u'come',\n",
       " u'endors',\n",
       " u'yesterday',\n",
       " u'#hero',\n",
       " u'#trump2016',\n",
       " u'brainwash',\n",
       " u'fucknut',\n",
       " u'alert',\n",
       " u'\\U0001f447\\U0001f447\\U0001f447\\U0001f447\\U0001f447\\U0001f447',\n",
       " u'#makeamericagreatagain',\n",
       " u'#trumptrain',\n",
       " u'#trump2016',\n",
       " u'retweet',\n",
       " u'map',\n",
       " u'rafael',\n",
       " u'cruz',\n",
       " u'cant',\n",
       " u'beat',\n",
       " u'hillarypol',\n",
       " u'end',\n",
       " u'feb',\n",
       " u'2016httpstcod1qfp84bnv',\n",
       " u'#trumptrain',\n",
       " u'#votetrump',\n",
       " u'#tru\\u2026',\n",
       " u'must',\n",
       " u'continu',\n",
       " u'fight',\n",
       " u'social',\n",
       " u'mediath',\n",
       " u'peopl',\n",
       " u'revolut',\n",
       " u'strongest',\n",
       " u'tool',\n",
       " u'right',\n",
       " u'#trump2016',\n",
       " u'#alwaystrump',\n",
       " u'hillari',\n",
       " u'could',\n",
       " u'lose',\n",
       " u'trump',\n",
       " u'democrat',\n",
       " u'new',\n",
       " u'york#makeamericagreatagain',\n",
       " u'#trump2016httpstcofqr48cvibt',\n",
       " u'white',\n",
       " u'supremacist',\n",
       " u'group',\n",
       " u'republican',\n",
       " u'parti',\n",
       " u'gunown',\n",
       " u'tea',\n",
       " u'parti',\n",
       " u'disagre',\n",
       " u'them#se\\u2026',\n",
       " u'truth',\n",
       " u'bomb',\n",
       " u'#trumpcommun',\n",
       " u'togeth',\n",
       " u'white',\n",
       " u'hous',\n",
       " u'#alwaystrump',\n",
       " u'#trump',\n",
       " u'muslim',\n",
       " u'come',\n",
       " u'2',\n",
       " u'#america',\n",
       " u'#stopthemad',\n",
       " u'#votetrump',\n",
       " u'#alwaystrump',\n",
       " u'#leapday',\n",
       " u'#tcot',\n",
       " u'#ccot',\n",
       " u'#makeamericagreatagain',\n",
       " u'donald',\n",
       " u'trump',\n",
       " u'crush',\n",
       " u'#rubio#cruz',\n",
       " u'earn',\n",
       " u'49',\n",
       " u'cnn',\n",
       " u'natl',\n",
       " u'poll#alwaystrump#secprimaryhttpstcowfl8la2srn',\n",
       " u'#marcorubio',\n",
       " u'#tedcruz',\n",
       " u'#hillaryclinton',\n",
       " u'vote',\n",
       " u'#alwaystrump',\n",
       " u'#donaldtrump',\n",
       " u'#trumptrain',\n",
       " u'#makeamericagreatagain',\n",
       " u'stand',\n",
       " u'springfield',\n",
       " u'plaza',\n",
       " u'springfieldva',\n",
       " u'tri',\n",
       " u'get',\n",
       " u'voter',\n",
       " u'mr',\n",
       " u'trump',\n",
       " u'#trump2016',\n",
       " u'time',\n",
       " u'vote',\n",
       " u'america',\n",
       " u'show',\n",
       " u'support',\n",
       " u'usa',\n",
       " u'trump',\n",
       " u'movement',\n",
       " u'#makeamericagreatagain',\n",
       " u'american',\n",
       " u'peopl',\n",
       " u'done',\n",
       " u'career',\n",
       " u'politiciansvot',\n",
       " u'trump',\n",
       " u'#alabama',\n",
       " u'#alprimari',\n",
       " u'#alwaystrump',\n",
       " u'#trump2016',\n",
       " u'donald',\n",
       " u'j',\n",
       " u'trump',\n",
       " u'49rubio',\n",
       " u'cruz',\n",
       " u'carson',\n",
       " u'kasich',\n",
       " u'47#makeamericagreatagain',\n",
       " u'#trump2016',\n",
       " u'#trumptrain\\U0001f682\\U0001f1fa\\U0001f1f8\\U0001f1fa\\U0001f1f8\\U0001f1fa\\U0001f1f8\\U0001f1fa\\U0001f1f8\\U0001f1fa\\U0001f1f8\\U0001f1fa\\U0001f1f8',\n",
       " u'#texasprimari',\n",
       " u'#texasvot',\n",
       " u'#texan',\n",
       " u'#secondamend',\n",
       " u'#makeamericagreatagain',\n",
       " u'#veteran',\n",
       " u'#senior',\n",
       " u'#collegestud',\n",
       " u'#usa',\n",
       " u'ht\\u2026',\n",
       " u'hillari',\n",
       " u'could',\n",
       " u'lose',\n",
       " u'trump',\n",
       " u'democrat',\n",
       " u'new',\n",
       " u'york#makeamericagreatagain',\n",
       " u'#trump2016httpstcofqr48cvibt',\n",
       " u'dont',\n",
       " u'want',\n",
       " u'hear',\n",
       " u'crass',\n",
       " u'trump',\n",
       " u'ok#drugtestrubio',\n",
       " u'#alwaystrump',\n",
       " u'#supertuesday',\n",
       " u'#marco',\n",
       " u'trump',\n",
       " u'support',\n",
       " u'#2a',\n",
       " u'right',\n",
       " u'peopl',\n",
       " u'keep',\n",
       " u'bear',\n",
       " u'arm',\n",
       " u'shall',\n",
       " u'infring',\n",
       " u'upon',\n",
       " u'period\\u201d',\n",
       " u'thank',\n",
       " u'endors',\n",
       " u'#makeamericagreatagain',\n",
       " u'#trump2016',\n",
       " u'#trumpforprez',\n",
       " u'exampl',\n",
       " u'side',\n",
       " u'trump',\n",
       " u'media',\n",
       " u'never',\n",
       " u'show',\n",
       " u'#trump2016',\n",
       " u'#makeamericagreatagain',\n",
       " u'wow',\n",
       " u'49',\n",
       " u'nation',\n",
       " u'poll',\n",
       " u'trump',\n",
       " u'landslid',\n",
       " u'brew',\n",
       " u'#onlytrump',\n",
       " u'#alwaystrump',\n",
       " u'#trumptrain',\n",
       " u'#makeamericagreatagain',\n",
       " u'incred',\n",
       " u'proud',\n",
       " u'call',\n",
       " u'oz',\n",
       " u'friend',\n",
       " u'oz',\n",
       " u'amp',\n",
       " u'tig',\n",
       " u'come',\n",
       " u'endors',\n",
       " u'yesterday',\n",
       " u'#hero',\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetList[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 : Collapsed Gibbs Sampler for Dynamic Topic Model\n",
    "Ref : \n",
    "1. Mimno (collapsed gibbs) http://dirichlet.net/pdf/mimno08gibbs.pdf\n",
    "2. Mimno (CG for logistic) http://psiexp.ss.uci.edu/research/papers/sciencetopics.pdf\n",
    "3. Blei (Dynamic Topic Modelling) http://www.stat.uchicago.edu/~lafferty/pdf/dtm.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from scipy.stats import truncnorm \n",
    "\n",
    "def sampleFromDiscrete(probs):\n",
    "    temp = random.random()\n",
    "    total =0\n",
    "    for i in range(len(probs)):\n",
    "        total+=probs[i]\n",
    "        if(temp<total):\n",
    "            return i\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Initialization of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Annotate words\n",
    "import numpy as np\n",
    "\n",
    "tweetHist0 = sc.parallelize(tweetList[0]).map(lambda w: vocab.index(w)).collect()\n",
    "tweetHist1 = sc.parallelize(tweetList[1]).map(lambda w: vocab.index(w)).collect()\n",
    "tweetHist2 = sc.parallelize(tweetList[2]).map(lambda w: vocab.index(w)).collect()\n",
    "tweetHist3 = sc.parallelize(tweetList[3]).map(lambda w: vocab.index(w)).collect()\n",
    "\n",
    "tweetHist = sc.parallelize([tweetHist0, tweetHist1, tweetHist2, tweetHist3])\\\n",
    "              .map(lambda y: np.bincount(y, minlength=len(vocab)))\n",
    "\n",
    "    \n",
    "N = tweetHist.count()\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pop from an empty set'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-e0102be958a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_vec\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdoc_vec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'pop from an empty set'"
     ]
    }
   ],
   "source": [
    "K=15\n",
    "alpha = np.ones(V)*0.1 #hyperparameter\n",
    "A = [alpha]*K\n",
    "beta = np.ones(K)\n",
    "pi = np.random.dirichlet(beta)\n",
    "pi1=pi\n",
    "theta = np.random.dirichlet(alpha, K)\n",
    "no_tweets = N\n",
    "doc_vec = tweetHist.collect()\n",
    "docs = set(range(0, N))\n",
    "z = [0]*N\n",
    "for i in range(K):\n",
    "    d = docs.pop()\n",
    "    z[d] = i\n",
    "    dist = np.linalg.norm(doc_vec - doc_vec[d], axis=1)\n",
    "    sorted_dist = np.argsort(dist)[0:N/K]\n",
    "    for k in sorted_dist:\n",
    "        docs.discard(k)\n",
    "        doc_vec[k] = [-inf]*len(doc_vec[0])\n",
    "        z[k] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "doc_vectors = tweetHist.collect()\n",
    "for i in range(200):\n",
    "    print bincount(z)\n",
    "    pi = np.random.dirichlet(betas + bincount(z, minlength=K))\n",
    "    sum_z = np.zeros((K, V))\n",
    "    for i in range(no_tweets):\n",
    "        sum_z[z[i]]+=doc_vectors[i]\n",
    "    for i in range(K):\n",
    "        theta[i] = np.random.dirichlet(A[i]+sum_z[i])\n",
    "    for d in range(no_tweets):\n",
    "        for i in range(K):\n",
    "            pi1[i]= np.dot(np.log(theta[i]),doc_vectors[d])\n",
    "        pi1 = np.exp(pi1-np.max(pi1))\n",
    "        for i in range(K):\n",
    "            pi1[i] *= pi[i]\n",
    "        pi1 = pi1/np.sum(pi1)\n",
    "        #print pi1\n",
    "        z[d]=sampleFromDiscrete(pi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1314 1561 1542 1423 1598 1518 1449 1404 1454 1468 1476 1284 1488 1464 1338]\n",
      "[700 761 738 790 701 683 749 688 672 702 627 676 750 803 702]\n",
      "[381 314 365 322 341 376 397 315 360 323 342 360 359 344 353]\n",
      "[586 613 617 589 571 653 531 642 492 535 599 628 655 701 571]\n"
     ]
    }
   ],
   "source": [
    "for i in range(D):\n",
    "    print np.bincount(z[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print len(theta)\n",
    "indices = argsort(theta, axis = 1)\n",
    "best = indices[:,-40:]\n",
    "for k in freq_class:\n",
    "    wordlist = [vocab[best[k][j]] for j in range(len(best[0]))]          \n",
    "    print wordlist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
